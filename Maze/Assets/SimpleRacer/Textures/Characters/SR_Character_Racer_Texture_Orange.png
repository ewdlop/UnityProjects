riteQuarterRate32] in {
defm V_SIN_F32 : VOP1Inst <"v_sin_f32", VOP_F32_F32, AMDGPUsin>;
defm V_COS_F32 : VOP1Inst <"v_cos_f32", VOP_F32_F32, AMDGPUcos>;
} // End SchedRW = [WriteQuarterRate32]

defm V_NOT_B32 : VOP1Inst <"v_not_b32", VOP_I32_I32>;
defm V_BFREV_B32 : VOP1Inst <"v_bfrev_b32", VOP_I32_I32>;
defm V_FFBH_U32 : VOP1Inst <"v_ffbh_u32", VOP_I32_I32>;
defm V_FFBL_B32 : VOP1Inst <"v_ffbl_b32", VOP_I32_I32>;
defm V_FFBH_I32 : VOP1Inst <"v_ffbh_i32", VOP_I32_I32>;
defm V_FREXP_EXP_I32_F64 : VOP1Inst <"v_frexp_exp_i32_f64", VOP_I32_F64, int_amdgcn_frexp_exp>;

let SchedRW = [WriteDoubleAdd] in {
defm V_FREXP_MANT_F64 : VOP1Inst <"v_frexp_mant_f64", VOP_F64_F64, int_amdgcn_frexp_mant>;
defm V_FRACT_F64 : VOP1Inst <"v_fract_f64", VOP_F64_F64, AMDGPUfract>;
} // End SchedRW = [WriteDoubleAdd]

defm V_FREXP_EXP_I32_F32 : VOP1Inst <"v_frexp_exp_i32_f32", VOP_I32_F32, int_amdgcn_frexp_exp>;
defm V_FREXP_MANT_F32 : VOP1Inst <"v_frexp_mant_f32", VOP_F32_F32, int_amdgcn_frexp_mant>;

let VOPAsmPrefer32Bit = 1 in {
defm V_CLREXCP : VOP1Inst <"v_clrexcp", VOP_NO_EXT<VOP_NONE>>;
}

// Restrict src0 to be VGPR
def VOP_I32_VI32_NO_EXT : VOPProfile<[i32, i32, untyped, untyped]> {
  let Src0RC32 = VRegSrc_32;
  let Src0RC64 = VRegSrc_32;

  let HasExt = 0;
  let HasSDWA9 = 0;
}

// Special case because there are no true output operands.  Hack vdst
// to be a src operand. The custom inserter must add a tied implicit
// def and use of the super register since there seems to be no way to
// add an implicit def of a virtual register in tablegen.
def VOP_MOVRELD : VOPProfile<[untyped, i32, untyped, untyped]> {
  let Src0RC32 = VOPDstOperand<VGPR_32>;
  let Src0RC64 = VOPDstOperand<VGPR_32>;

  let Outs = (outs);
  let Ins32 = (ins Src0RC32:$vdst, VSrc_b32:$src0);
  let Ins64 = (ins Src0RC64:$vdst, VSrc_b32:$src0);
  let InsDPP = (ins DstRC:$vdst, DstRC:$old, Src0RC32:$src0,
                    dpp_ctrl:$dpp_ctrl, row_mask:$row_mask,
                    bank_mask:$bank_mask, bound_ctrl:$bound_ctrl);

  let InsSDWA = (ins Src0RC32:$vdst, Src0ModSDWA:$src0_modifiers, Src0SDWA:$src0,
                     clampmod:$clamp, omod:$omod, dst_sel:$dst_sel, dst_unused:$dst_unused,
                     src0_sel:$src0_sel);

  let Asm32 = getAsm32<1, 1>.ret;
  let Asm64 = getAsm64<1, 1, 0, 0, 1>.ret;
  let AsmDPP = getAsmDPP<1, 1, 0>.ret;
  let AsmSDWA = getAsmSDWA<1, 1>.ret;
  let AsmSDWA9 = getAsmSDWA9<1, 0, 1>.ret;

  let HasExt = 0;
  let HasSDWA9 = 0;
  let HasDst = 0;
  let EmitDst = 1; // force vdst emission
}

let SubtargetPredicate = HasMovrel, Uses = [M0, EXEC] in {
// v_movreld_b32 is a special case because the destination output
 // register is really a source. It isn't actually read (but may be
 // written), and is only to provide the base register to start
 // indexing from. Tablegen seems to not let you define an implicit
 // virtual register output for the super register being written into,
 // so this must have an implicit def of the register added to it.
defm V_MOVRELD_B32 : VOP1Inst <"v_movreld_b32", VOP_MOVRELD>;
defm V_MOVRELS_B32 : VOP1Inst <"v_movrels_b32", VOP_I32_VI32_NO_EXT>;
defm V_MOVRELSD_B32 : VOP1Inst <"v_movrelsd_b32", VOP_NO_EXT<VOP_I32_I32>>;
} // End Uses = [M0, EXEC]

let SchedRW = [WriteQuarterRate32] in {
defm V_MOV_FED_B32 : VOP1Inst <"v_mov_fed_b32", VOP_I32_I32>;
}

// These instruction only exist on SI and CI
let SubtargetPredicate = isSICI in {

let SchedRW = [WriteQuarterRate32] in {
defm V_LOG_CLAMP_F32 : VOP1Inst <"v_log_clamp_f32", VOP_F32_F32, int_amdgcn_log_clamp>;
defm V_RCP_CLAMP_F32 : VOP1Inst <"v_rcp_clamp_f32", VOP_F32_F32>;
defm V_RCP_LEGACY_F32 : VOP1Inst <"v_rcp_legacy_f32", VOP_F32_F32, AMDGPUrcp_legacy>;
defm V_RSQ_CLAMP_F32 : VOP1Inst <"v_rsq_clamp_f32", VOP_F32_F32, AMDGPUrsq_clamp>;
defm V_RSQ_LEGACY_F32 : VOP1Inst <"v_rsq_legacy_f32", VOP_F32_F32, AMDGPUrsq_legacy>;
} // End SchedRW = [WriteQuarterRate32]

let SchedRW = [WriteDouble] in {
defm V_RCP_CLAMP_F64 : VOP1Inst <"v_rcp_clamp_f64", VOP_F64_F64>;
defm V_RSQ_CLAMP_F64 : VOP1Inst <"v_rsq_clamp_f64", VOP_F64_F64, AMDGPUrsq_clamp>;
} // End SchedRW = [WriteDouble]

} // End SubtargetPredicate = isSICI


let SubtargetPredicate = isCIVI in {

let SchedRW = [WriteDoubleAdd] in {
defm V_TRUNC_F64 : VOP1Inst <"v_trunc_f64", VOP_F64_F64, ftrunc>;
defm V_CEIL_F64 : VOP1Inst <"v_ceil_f64", VOP_F64_F64, fceil>;
defm V_FLOOR_F64 : VOP1Inst <"v_floor_f64", VOP_F64_F64, ffloor>;
defm V_RNDNE_F64 : VOP1Inst <"v_rndne_f64", VOP_F64_F64, frint>;
} // End SchedRW = [WriteDoubleAdd]

let SchedRW = [WriteQuarterRate32] in {
defm V_LOG_LEGACY_F32 : VOP1Inst <"v_log_legacy_f32", VOP_F32_F32>;
defm V_EXP_LEGACY_F32 : VOP1Inst <"v_exp_legacy_f32", VOP_F32_F32>;
} // End SchedRW = [WriteQuarterRate32]

} // End SubtargetPredicate = isCIVI


let SubtargetPredicate = Has16BitInsts in {

defm V_CVT_F16_U16 : VOP1Inst <"v_cvt_f16_u16", VOP1_F16_I16, uint_to_fp>;
defm V_CVT_F16_I16 : VOP1Inst <"v_cvt_f16_i16", VOP1_F16_I16, sint_to_fp>;
defm V_CVT_U16_F16 : VOP1Inst <"v_cvt_u16_f16", VOP_I16_F16, fp_to_uint>;
defm V_CVT_I16_F16 : VOP1Inst <"v_cvt_i16_f16", VOP_I16_F16, fp_to_sint>;
defm V_RCP_F16 : VOP1Inst <"v_rcp_f16", VOP_F16_F16, AMDGPUrcp>;
defm V_SQRT_F16 : VOP1Inst <"v_sqrt_f16", VOP_F16_F16, fsqrt>;
defm V_RSQ_F16 : VOP1Inst <"v_rsq_f16", VOP_F16_F16, AMDGPUrsq>;
defm V_LOG_F16 : VOP1Inst <"v_log_f16", VOP_F16_F16, flog2>;
defm V_EXP_F16 : VOP1Inst <"v_exp_f16", VOP_F16_F16, fexp2>;
defm V_FREXP_MANT_F16 : VOP1Inst <"v_frexp_mant_f16", VOP_F16_F16, int_amdgcn_frexp_mant>;
defm V_FREXP_EXP_I16_F16 : VOP1Inst <"v_frexp_exp_i16_f16", VOP_I16_F16, int_amdgcn_frexp_exp>;
defm V_FLOOR_F16 : VOP1Inst <"v_floor_f16", VOP_F16_F16, ffloor>;
defm V_CEIL_F16 : VOP1Inst <"v_ceil_f16", VOP_F16_F16, fceil>;
defm V_TRUNC_F16 : VOP1Inst <"v_trunc_f16", VOP_F16_F16, ftrunc>;
defm V_RNDNE_F16 : VOP1Inst <"v_rndne_f16", VOP_F16_F16, frint>;
defm V_FRACT_F16 : VOP1Inst <"v_fract_f16", VOP_F16_F16, AMDGPUfract>;
defm V_SIN_F16 : VOP1Inst <"v_sin_f16", VOP_F16_F16, AMDGPUsin>;
defm V_COS_F16 : VOP1Inst <"v_cos_f16", VOP_F16_F16, AMDGPUcos>;

}

let OtherPredicates = [Has16BitInsts] in {

def : GCNPat<
    (f32 (f16_to_fp i16:$src)),
    (V_CVT_F32_F16_e32 $src)
>;

def : GCNPat<
    (i16 (AMDGPUfp_to_f16 f32:$src)),
    (V_CVT_F16_F32_e32 $src)
>;

}

def VOP_SWAP_I32 : VOPProfile<[i32, i32, i32, untyped]> {
  let Outs32 = (outs VGPR_32:$vdst, VGPR_32:$vdst1);
  let Ins32 = (ins VGPR_32:$src0, VGPR_32:$src1);
  let Outs64 = Outs32;
  let Asm32 = " $vdst, $src0";
  let Asm64 = "";
  let Ins64 = (ins);
}

let SubtargetPredicate = isGFX9 in {
  let Constraints = "$vdst = $src1, $vdst1 = $src0",
      DisableEncoding="$vdst1,$src1",
      SchedRW = [Write64Bit, Write64Bit] in {
// Never VOP3. Takes as long as 2 v_mov_b32s
def V_SWAP_B32 : VOP1_Pseudo <"v_swap_b32", VOP_SWAP_I32, [], 1>;
}

} // End SubtargetPredicate = isGFX9

//===----------------------------------------------------------------------===//
// Target
//===----------------------------------------------------------------------===//

//===----------------------------------------------------------------------===//
// SI
//===----------------------------------------------------------------------===//

multiclass VOP1_Real_si <bits<9> op> {
  let AssemblerPredicates = [isSICI], DecoderNamespace = "SICI" in {
    def _e32_si :
      VOP1_Real<!cast<VOP1_Pseudo>(NAME#"_e32"), SIEncodingFamily.SI>,
      VOP1e<op{7-0}, !cast<VOP1_Pseudo>(NAME#"_e32").Pfl>;
    def _e64_si :
      VOP3_Real<!cast<VOP3_Pseudo>(NAME#"_e64"), SIEncodingFamily.SI>,
      VOP3e_si <{1, 1, op{6-0}}, !cast<VOP3_Pseudo>(NAME#"_e64").Pfl>;
  }
}

defm V_NOP               : VOP1_Real_si <0x0>;
defm V_MOV_B32           : VOP1_Real_si <0x1>;
defm V_CVT_I32_F64       : VOP1_Real_si <0x3>;
defm V_CVT_F64_I32       : VOP1_Real_si <0x4>;
defm V_CVT_F32_I32       : VOP1_Real_si <0x5>;
defm V_CVT_F32_U32       : VOP1_Real_si <0x6>;
defm V_CVT_U32_F32       : VOP1_Real_si <0x7>;
defm V_CVT_I32_F32       : VOP1_Real_si <0x8>;
defm V_MOV_FED_B32       : VOP1_Real_si <0x9>;
defm V_CVT_F16_F32       : VOP1_Real_si <0xa>;
defm V_CVT_F32_F16       : VOP1_Real_si <0xb>;
defm V_CVT_RPI_I32_F32   : VOP1_Real_si <0xc>;
defm V_CVT_FLR_I32_F32   : VOP1_Real_si <0xd>;
defm V_CVT_OFF_F32_I4    : VOP1_Real_si <0xe>;
defm V_CVT_F32_F64       : VOP1_Real_si <0xf>;
defm V_CVT_F64_F32       : VOP1_Real_si <0x10>;
defm V_CVT_F32_UBYTE0    : VOP1_Real_si <0x11>;
defm V_CVT_F32_UBYTE1    : VOP1_Real_si <0x12>;
defm V_CVT_F32_UBYTE2    : VOP1_Real_si <0x13>;
defm V_CVT_F32_UBYTE3    : VOP1_Real_si <0x14>;
defm V_CVT_U32_F64       : VOP1_Real_si <0x15>;
defm V_CVT_F64_U32       : VOP1_Real_si <0x16>;
defm V_FRACT_F32         : VOP1_Real_si <0x20>;
defm V_TRUNC_F32         : VOP1_Real_si <0x21>;
defm V_CEIL_F32          : VOP1_Real_si <0x22>;
defm V_RNDNE_F32         : VOP1_Real_si <0x23>;
defm V_FLOOR_F32         : VOP1_Real_si <0x24>;
defm V_EXP_F32           : VOP1_Real_si <0x25>;
defm V_LOG_CLAMP_F32     : VOP1_Real_si <0x26>;
defm V_LOG_F32           : VOP1_Real_si <0x27>;
defm V_RCP_CLAMP_F32     : VOP1_Real_si <0x28>;
defm V_RCP_LEGACY_F32    : VOP1_Real_si <0x29>;
defm V_RCP_F32           : VOP1_Real_si <0x2a>;
defm V_RCP_IFLAG_F32     : VOP1_Real_si <0x2b>;
defm V_RSQ_CLAMP_F32     : VOP1_Real_si <0x2c>;
defm V_RSQ_LEGACY_F32    : VOP1_Real_si <0x2d>;
defm V_RSQ_F32           : VOP1_Real_si <0x2e>;
defm V_RCP_F64           : VOP1_Real_si <0x2f>;
defm V_RCP_CLAMP_F64     : VOP1_Real_si <0x30>;
defm V_RSQ_F64           : VOP1_Real_si <0x31>;
defm V_RSQ_CLAMP_F64     : VOP1_Real_si <0x32>;
defm V_SQRT_F32          : VOP1_Real_si <0x33>;
defm V_SQRT_F64          : VOP1_Real_si <0x34>;
defm V_SIN_F32           : VOP1_Real_si <0x35>;
defm V_COS_F32           : VOP1_Real_si <0x36>;
defm V_NOT_B32           : VOP1_Real_si <0x37>;
defm V_BFREV_B32         : VOP1_Real_si