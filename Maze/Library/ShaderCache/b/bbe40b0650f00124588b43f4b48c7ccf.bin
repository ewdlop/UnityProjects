/*
 * Copyright (c) 2008-2017, NVIDIA CORPORATION.  All rights reserved.
 *
 * NVIDIA CORPORATION and its licensors retain all intellectual property
 * and proprietary rights in and to this software, related documentation
 * and any modifications thereto.  Any use, reproduction, disclosure or
 * distribution of this software and related documentation without an express
 * license agreement from NVIDIA CORPORATION is strictly prohibited.
 */


#include "Cooking.h"

#include <PsArray.h>
#include <PsMathUtils.h>
#include <PsSort.h>
#include <Ps.h>

#include <ApexSDKIntl.h>

#include "ClothingCookedPhysX3Param.h"

#include "ExtClothFabricCooker.h"
#include "ExtClothMeshQuadifier.h"

#include "ModuleClothingHelpers.h"

#include <ctime>

namespace
{
	using namespace nvidia;
	
	struct VirtualParticle
	{
		VirtualParticle(uint32_t i0, uint32_t i1, uint32_t i2)
		{
			indices[0] = i0;
			indices[1] = i1;
			indices[2] = i2;
			tableIndex = 0;
		}

		void rotate(uint32_t count)
		{
			while (count--)
			{
				const uint32_t temp = indices[2];
				indices[2] = indices[1];
				indices[1] = indices[0];
				indices[0] = temp;
			}
		}

		uint32_t indices[3];
		uint32_t tableIndex;
	};

	struct EdgeAndLength
	{
		EdgeAndLength(uint32_t edgeNumber, float length) : mEdgeNumber(edgeNumber), mLength(length) {}
		uint32_t mEdgeNumber;
		float mLength;

		bool operator<(const EdgeAndLength& other) const
		{
			return mLength < other.mLength;
		}
	};
}

namespace nvidia
{
namespace clothing
{

bool Cooking::mTetraWarning = false;

NvParameterized::Interface* Cooking::execute()
{
	ClothingCookedPhysX3Param* rootCookedData = NULL;

	for (uint32_t meshIndex = 0; meshIndex < mPhysicalMeshes.size(); meshIndex++)
	{
		if (mPhysicalMeshes[meshIndex].isTetrahedral)
		{
			if (!mTetraWarning)
			{
				mTetraWarning = true;
				APEX_INVALID_OPERATION("Tetrahedral meshes are not (yet) supported with the 3.x solver");
			}
			continue;
		}

		ClothingCookedPhysX3Param* cookedData = NULL;

		cookedData = fiberCooker(meshIndex);

		computeVertexWeights(cookedData, meshIndex);
		fillOutSetsDesc(cookedData);

		createVirtualParticles(cookedData, meshIndex);
		createSelfcollisionIndices(cookedData, meshIndex);

		if (rootCookedData == NULL)
		{
			rootCookedData = cookedData;
		}
		else
		{
			ClothingCookedPhysX3Param* addCookedData = rootCookedData;
			while (addCookedData != NULL && addCookedData->nextCookedData != NULL)
			{
				addCookedData = static_cast<ClothingCookedPhysX3Param*>(addCookedData->nextCookedData);
			}
			addCookedData->nextCookedData = cookedData;
		}
	}

	return rootCookedData;
}



ClothingCookedPhysX3Param* Cooking::fiberCooker(uint32_t meshIndex) const
{
	const uint32_t numSimulatedVertices = mPhysicalMeshes[meshIndex].numSimulatedVertices;
	const uint32_t numAttached = mPhysicalMeshes[meshIndex].numMaxDistance0Vertices;

	shdfnd::Array<PxVec4> vertices(numSimulatedVertices);
	for (uint32_t i = 0; i < numSimulatedVertices; i++)
		vertices[i] = PxVec4(mPhysicalMeshes[meshIndex].vertices[i], 1.0f);

	if (numAttached > 0)
	{
		const uint32_t start = numSimulatedVertices - numAttached;
		for (uint32_t i = start; i < numSimulatedVertices; i++)
			vertices[i].w = 0.0f;
	}

	PxClothMeshDesc desc;

	desc.points.data = vertices.begin();
	desc.points.count = numSimulatedVertices;
	desc.points.stride = sizeof(PxVec4);

	desc.invMasses.data = &vertices.begin()->w;
	desc.invMasses.count = numSimulatedVertices;
	desc.invMasses.stride = sizeof(PxVec4);

	desc.triangles.data = mPhysicalMeshes[meshIndex].indices;
	desc.triangles.count = mPhysicalMeshes[meshIndex].numSimulatedIndices / 3;
	desc.triangles.stride = sizeof(uint32_t) * 3;

	PxClothMeshQuadifier quadifier(desc);

	PxClothFabricCooker cooker(quadifier.getDescriptor(), mGravityDirection);
	
	PxClothFabricDesc fabric = cooker.getDescriptor(); 

	int32_t nbConstraints = (int32_t)fabric.sets[fabric.nbSets - 1];

	ClothingCookedPhysX3Param* cookedData = NULL;

	bool success = true;
	if (success)
	{
		cookedData = static_cast<ClothingCookedPhysX3Param*>(GetInternalApexSDK()->getParameterizedTraits()->createNvParameterized(ClothingCookedPhysX3Param::staticClassName()));

		NvParameterized::Handle arrayHandle(cookedData);
		arrayHandle.getParameter("deformableIndices");
		arrayHandle.resizeArray(nbConstraints * 2);
		arrayHandle.setParamU32Array(fabric.indices, nbConstraints * 2);

		arrayHandle.getParameter("deformableRestLengths");
		arrayHandle.resizeArray(nbConstraints);
		arrayHandle.setParamF32Array(fabric.restvalues, nbConstraints);

		arrayHandle.getParameter("deformableSets");
		const int32_t numSets = (int32_t)fabric.nbSets;
		arrayHandle.resizeArray(numSets);
		for (int32_t i = 0; i < numSets; i++)
		{
			arrayHandle.set(i);
			arrayHandle.set(0);
			arrayHandle.setParamU32(fabric.sets[(uint32_t)i]);
			arrayHandle.popIndex();
			arrayHandle.popIndex();
		}

		arrayHandle.getParameter("deformablePhaseDescs");
		arrayHandle.resizeArray((int32_t)fabric.nbPhases);

		for (uint32_t i = 0; i < fabric.nbPhases; i++)
		{
			PxClothFabricPhase phase = fabric.phases[i];
			cookedData->deformablePhaseDescs.buf[i].phaseType = phase.phaseType;
			cookedData->deformablePhaseDescs.buf[i].setIndex = phase.setIndex;
		}

		arrayHandle.getParameter("tetherAnchors");
		arrayHandle.resizeArray((int32_t)fabric.nbTethers);
		arrayHandle.setParamU32Array(fabric.tetherAnchors, (int32_t)fabric.nbTethers);

		arrayHandle.getParameter("tetherLengths");
		arrayHandle.resizeArray((int32_t)fabric.nbTethers);
		arrayHandle.setParamF32Array(fabric.tetherLengths, (int32_t)fabric.nbTethers);

		cookedData->physicalMeshId = meshIndex;
		cookedData->numVertices = numSimulatedVertices;

		//dumpObj("c:\\lastCooked.obj", meshIndex);
		//dumpApx("c:\\lastCooked.apx", cookedData);

		cookedData->cookedDataVersion = getCookingVersion();
	}
	else
	{
#if PX_WINDOWS_FAMILY
		static int failureCount = 0;
		char buf[64];
		sprintf_s(buf, 64, "c:\\cookingFailure_%d.obj", failureCount++);
		dumpObj(buf, meshIndex);

		APEX_INTERNAL_ERROR("Fiber cooking failure (mesh %d), the failing mesh has been dumped to \'%s\'", meshIndex, buf);
#else
		APEX_INTERNAL_ERROR("Fiber cooking failure (mesh %d)", meshIndex);
#endif

	}


	return cookedData;
}

void Cooking::computeVertexWeights(ClothingCookedPhysX3Param* cookedData, uint32_t meshIndex) const
{
	const uint32_t* indices					= mPhysicalMeshes[cookedData->physicalMeshId].indices;
	const PxVec3*	positions				= mPhysicalMeshes[cookedData->physicalMeshId].vertices;
	const uint32_t	numSimulatedIndices		= mPhysicalMeshes[meshIndex].numSimulatedIndices;
	const uint32_t	numSimulatedVertices	= mPhysicalMeshes[meshIndex].numSimulatedVertices;

	nvidia::Array<float> weights(numSimulatedVertices, 0.0f);

	PX_ASSERT(numSimulatedIndices % 3 == 0);
	for (uint32_t i = 0; i < numSimulatedIndices; i += 3)
	{
		const PxVec3 v1 = positions[indices[i + 1]] - positions[indices[i]];
		const PxVec3 v2 = positions[indices[i + 2]] - positions[indices[i]];
		const float area = v1.cross(v2).magnitude();

		for (uint32_t j = 0; j < 3; j++)
		{
			weights[indices[i + j]] += area;
		}
	}

	float weightSum = 0.0f;
	for (uint32_t i = 0; i < numSimulatedVertices; i++)
	{
		weightSum += weights[i];
	}

	const float weightScale = (float)numSimulatedVertices / weightSum;

	for (uint32_t i = 0; i < numSimulatedVertices; i++)
	{
		weights[i] *= weightScale;
	}

	NvParameterized::Handle handle(*cookedData, "deformableInvVertexWeights");
	if (handle.resizeArray((int32_t)numSimulatedVertices) == NvParameterized::ERROR_NONE)
	{
		for (uint32_t i = 0; i < numSimulatedVertices; i++)
		{
			cookedData->deformableInvVertexWeights.buf[i] = 1.0f / weights[i];
		}
	}
}



void Cooking::createVirtualParticles(ClothingCookedPhysX3Param* cookedData, uint32_t meshIndex)
{
	const PxVec3*	positions	= mPhysicalMeshes[cookedData->physicalMeshId].vertices;
	const uint32_t* indices		= mPhysicalMeshes[cookedData->physicalMeshId].indices;
	const uint32_t	numIndices	= mPhysicalMeshes[meshIndex].numSimulatedIndices;

	nvidia::Array<VirtualParticle> particles;

	const float minTriangleArea = mVirtualParticleDensity * mPhysicalMeshes[cookedData->physicalMeshId].smallestTriangleArea / 2.0f +
	                              (1.0f - mVirtualParticleDensity) * mPhysicalMeshes[cookedData->physicalMeshId].largestTriangleArea;
	const float coveredTriangleArea = minTriangleArea;

	for (uint32_t i = 0; i < numIndices; i += 3)
	{
		VirtualParticle particle(indices[i], indices[i + 1], indices[i + 2]);

		const PxVec3 edge1 = positions[particle.indices[1]] - positions[particle.indices[0]];
		const PxVec3 edge2 = positions[particle.indices[2]] - positions[particle.indices[0]];
		const float triangleArea = edge1.cross(edge2).magnitude();

		const float numSpheres = triangleArea / coveredTriangleArea;

		if (numSpheres <= 1.0f)
		{
			// do nothing
		}
		else if (numSpheres < 2.0f)
		{
			// add one virtual particle
			particles.pushBack(particle);
		}
		else
		{
			// add two or three, depending on whether it's a slim triangle.
			EdgeAndLength eal0(0, edge1.magnitude());
			EdgeAndLength eal1(1, (positions[particle.indices[2]] - positions[particle.indices[1]]).magnitude());
			EdgeAndLength eal2(2, edge2.magnitude());
			EdgeAndLength middle = eal0 < eal1 ? eal0 : eal1; // technically this does not have to be the middle of the three, but for the test below it suffices.
			EdgeAndLength smallest = middle < eal2 ? middle : eal2;
			if (smallest.mLength * 2.0f < middle.mLength)
			{
				// two
				particle.rotate(smallest.mEdgeNumber);
				particle.tableIndex = 2;
				particles.pushBack(particle);
				particle.tableIndex = 3;
				particles.pushBack(particle);
			}
			else
			{
				// three
				particle.tableIndex = 1;
				particles.pushBack(particle);
				particle.rotate(1);
				particles.pushBack(particle);
				particle.rotate(1);
				particles.pushBack(particle);
			}
		}
	}

	if (!particles.empty())
	{
		NvParameterized::Handle handle(cookedData);
		handle.getParameter("virtualParticleIndices");
		handle.resizeArray((int32_t)particles.size() * 4);
		handle.getParameter("virtualParticleWeights");
		handle.resizeArray(3 * 4);

		// table index 0, the center particle
		cookedData->virtualParticleWeights.buf[0] = 1.0f / 3.0f;
		cookedData->virtualParticleWeights.buf[1] = 1.0f / 3.0f;
		cookedData->virtualParticleWeights.buf[2] = 1.0f / 3.0f;

		// table index 1, three particles
		cookedData->virtualParticleWeights.buf[3] = 0.1f;
		cookedData->virtualParticleWeights.buf[4] = 0.3f;
		cookedData->virtualParticleWeights.buf[5] = 0.6f;

		// table index 2, the pointy particle
		cookedData->virtualParticleWeights.buf[6] = 0.7f;
		cookedData->virtualParticleWeights.buf[7] = 0.15f;
		cookedData->virtualParticleWeights.buf[8] = 0.15f;

		// table index 3, the flat particle
		cookedData->virtualParticleWeights.buf[9] = 0.3f;
		cookedData->virtualParticleWeights.buf[10] = 0.35f;
		cookedData->virtualParticleWeights.buf[11] = 0.35f;

		for (uint32_t i = 0; i < particles.size(); i++)
		{
			for (uint32_t j = 0; j < 3; j++)
			{
				cookedData->virtualParticleIndices.buf[4 * i + j] = particles[i].indices[j];
			}
			cookedData->virtualParticleIndices.buf[4 * i + 3] = particles[i].tableIndex; // the table index
		}
	}
}


void Cooking::createSelfcollisionIndices(ClothingCookedPhysX3Param* cookedData, uint32_t meshIndex) const
{
	const PxVec3*	positions	= mPhysicalMeshes[cookedData->physicalMeshId].vertices;
	const uint32_t	numVertices = mPhysicalMeshes[meshIndex].numSimulatedVertices;


	// we'll start with a full set of indices, and eliminate the ones we don't want. selfCollisionIndices
	//  is an array of indices, i.e. a second layer of indirection
	Array<uint32_t> selfCollisionIndices;
	for (uint32_t i = 0; i < numVertices; ++i)
	{
		selfCollisionIndices.pushBack(i);
	}

	float selfcollisionThicknessSq = mSelfcollisionRadius * mSelfcollisionRadius;
	for (uint32_t v0ii = 0; v0ii < selfCollisionIndices.size(); ++v0ii)
	{
		// ii suffix means "index into indices array", i suffix just means "index into vertex array"

		// load the first vertex
		uint32_t v0i = selfCollisionIndices[v0ii];
		const PxVec3& v0 = positions[v0i];

		// no need to start at the beginning of the array, those comparisons have already been made.
		// don't autoincrement the sequence index. if we eliminate an 