"""
Import utilities

Exported classes:
    ImportManager   Manage the import process

    Importer        Base class for replacing standard import functions
    BuiltinImporter Emulate the import mechanism for builtin and frozen modules

    DynLoadSuffixImporter
"""
from warnings import warnpy3k
warnpy3k("the imputil module has been removed in Python 3.0", stacklevel=2)
del warnpy3k

# note: avoid importing non-builtin modules
import imp                      ### not available in Jython?
import sys
import __builtin__

# for the DirectoryImporter
import struct
import marshal

__all__ = ["ImportManager","Importer","BuiltinImporter"]

_StringType = type('')
_ModuleType = type(sys)         ### doesn't work in Jython...

class ImportManager:
    "Manage the import process."

    def install(self, namespace=vars(__builtin__)):
        "Install this ImportManager into the specified namespace."

        if isinstance(namespace, _ModuleType):
            namespace = vars(namespace)

        # Note: we have no notion of "chaining"

        # Record the previous import hook, then install our own.
        self.previous_importer = namespace['__import__']
        self.namespace = namespace
        namespace['__import__'] = self._import_hook

        ### fix this
        #namespace['reload'] = self._reload_hook

    def uninstall(self):
        "Restore the previous import mechanism."
        self.namespace['__import__'] = self.previous_importer

    def add_suffix(self, suffix, importFunc):
        assert hasattr(importFunc, '__call__')
        self.fs_imp.add_suffix(suffix, importFunc)

    ######################################################################
    #
    # PRIVATE METHODS
    #

    clsFilesystemImporter = None

    def __init__(self, fs_imp=None):
        # we're definitely going to be importing something in the future,
        # so let's just load the OS-related facilities.
        if not _os_stat:
            _os_bootstrap()

        # This is the Importer that we use for grabbing stuff from the
        # filesystem. It defines one more method (import_from_dir) for our use.
        if fs_imp is None:
            cls = self.clsFilesystemImporter or _FilesystemImporter
            fs_imp = cls()
        self.fs_imp = fs_imp

        # Initialize the set of suffixes that we recognize and import.
        # The default will import dynamic-load modules first, followed by
        # .py files (or a .py file's cached bytecode)
        for desc in imp.get_suffixes():
            if desc[2] == imp.C_EXTENSION:
                self.add_suffix(desc[0],
                                DynLoadSuffixImporter(desc).import_file)
        self.add_suffix('.py', py_suffix_importer)

    def _import_hook(self, fqname, globals=None, locals=None, fromlist=None):
        """Python calls this hook to locate and import a module."""

        parts = fqname.split('.')

        # determine the context of this import
        parent = self._determine_import_context(globals)

        # if there is a parent, then its importer should manage this import
        if parent:
            module = parent.__importer__._do_import(parent, parts, fromlist)
            if module:
                return module

        # has the top module already been imported?
        try:
            top_module = sys.modules[parts[0]]
        except KeyError:

            # look for the topmost module
            top_module = self._import_top_module(parts[0])
            if not top_module:
                # the topmost module wasn't found at all.
                raise ImportError, 'No module named ' + fqname

        # fast-path simple imports
        if len(parts) == 1:
            if not fromlist:
                return top_module

            if not top_module.__dict__.get('__ispkg__'):
                # __ispkg__ isn't defined (the module was not imported by us),
                # or it is zero.
                #
                # In the former case, there is no way that we could import
                # sub-modules that occur in the fromlist (but we can't raise an
                # error because it may just be names) because we don't know how
                # to deal with packages that were imported by other systems.
                #
                # In the latter case (__ispkg__ == 0), there can't be any sub-
                # modules present, so we can just return.
                #
                # In both cases, since len(parts) == 1, the top_module is also
                # the "bottom" which is the defined return when a fromlist
                # exists.
                return top_module

        importer = top_module.__dict__.get('__importer__')
        if importer:
            return importer._finish_import(top_module, parts[1:], fromlist)

        # Grrr, some people "import os.path" or do "from os.path import ..."
        if len(parts) == 2 and hasattr(top_module, parts[1]):
            if fromlist:
                return getattr(top_module, parts[1])
            else:
                return top_module

        # If the importer does not exist, then we have to bail. A missing
        # importer means that something else imported the module, and we have
        # no knowledge of how to get sub-modules out of the thing.
        raise ImportError, 'No module named ' + fqname

    def _determine_import_context(self, globals):
        """Returns the context in which a module should be imported.

        The context could be a loaded (package) module and the imported module
        will be looked for within that package. The context could also be None,
        meaning there is no context -- the module should be looked for as a
        "top-level" module.
        """

        if not globals or not globals.get('__importer__'):
            # globals does not refer to one of our modules or packages. That
            # implies there is no relative import context (as far as we are
            # concerned), and it should just pick it off the standard path.
            return None

        # The globals refer to a module or package of ours. It will define
        # the context of the new import. Get the module/package fqname.
        parent_fqname = globals['__name__']

        # if a package is performing the import, then return itself (imports
        # refer to pkg contents)
        if globals['__ispkg__']:
            parent = sys.modules[parent_fqname]
            assert globals is parent.__dict__
            return parent

        i = parent_fqname.rfind('.')

        # a module outside of a package has no particular import context
        if i == -1:
            return None

        # if a module in a package is performing the import, then return the
        # package (imports refer to siblings)
        parent_fqname = parent_fqname[:i]
        parent = sys.modules[parent_fqname]
        assert parent.__name__ == parent_fqname
        return parent

    def _import_top_module(self, name):
        # scan sys.path looking for a location in the filesystem that contains
        # the module, or an Importer object that can import the module.
        for item in sys.path:
            if isinstance(item, _StringType):
                module = self.fs_imp.import_from_dir(item, name)
            else:
                module = item.import_top(name)
            if module:
                return module
        return None

    def _reload_hook(self, module):
        "Python calls this hook to reload a module."

        # reloading of a module may or may not be possible (depending on the
        # importer), but at least we can validate that it's ours to reload
        importer = module.__dict__.get('__importer__')
        if not importer:
            ### oops. now what...
            pass

        # okay. it is using the imputil system, and we must delegate it, but
        # we don't know what to do (yet)
        ### we should blast the module dict and do another get_code(). need to
        ### flesh this out and add proper docco...
        raise SystemError, "reload not yet implemented"


class Importer:
    "Base class for replacing standard import functions."

    def import_top(self, name):
        "Import a top-level module."
        return self._import_one(None, name, name)

    ######################################################################
    #
    # PRIVATE METHODS
    #
    def _finish_import(self, top, parts, fromlist):
        # if "a.b.c" was provided, then load the ".b.c" portion down from
        # below the top-level module.
        bottom = self._load_tail(top, parts)

        # if the form is "import a.b.c", then return "a"
        if not fromlist:
            # no fromlist: return the top of the import tree
            return top

        # the top module was imported by self.
        #
        # this means that the bottom module was also imported by self (just
        # now, or in the past and we fetched it from sys.modules).
        #
        # since we imported/handled the bottom module, this means that we can
        # also handle its fromlist (and reliably use __ispkg__).

        # if the bottom node is a package, then (potentially) import some
        # modules.
        #
        # note: if it is not a package, then "fromlist" refers to names in
        #       the bottom module rather than modules.
        # note: for a mix of names and modules in the fromlist, we will
        #       import all modules and insert those into the namespace of
        #       the package module. Python will pick up all fromlist names
        #       from the bottom (package) module; some will be modules that
        #       we imported and stored in the namespace, others are expected
        #       to be present already.
        if bottom.__ispkg__:
            self._import_fromlist(bottom, fromlist)

        # if the form is "from a.b import c, d" then return "b"
        return bottom

    def _import_one(self, parent, modname, fqname):
        "Import a single module."

        # has the module already been imported?
        try:
            return sys.modules[fqname]
        except KeyError:
            pass

        # load the module's code, or fetch the module itself
        result = self.get_code(parent, modname, fqname)
        if result is None:
            return None

        module = self._process_result(result, fqname)

        # insert the module into its parent
        if parent:
            setattr(parent, modname, module)
        return module

    def _process_result(self, result, fqname):
        ispkg, code, values = result
        # did get_code() return an actual module? (rather than a code object)
        is_module = isinstance(code, _ModuleType)

        # use the returned module, or create a new one to exec code into
        if is_module:
            module = code
        else:
            module = imp.new_module(fqname)

        ### record packages a bit differently??
        module.__importer__ = self
        module.__ispkg__ = ispkg

        # insert additional values into the module (before executing the code)
        module.__dict__.update(values)

        # the module is almost ready... make it visible
        sys.modules[fqname] = module

        # execute the code within the module's namespace
        if not is_module:
            try:
                exec code in module.__dict__
            except:
                if fqname in sys.modules:
                    del sys.modules[fqname]
                raise

        # fetch from sys.modules instead of returning module directly.
        # also make module's __name__ agree with fqname, in case
        # the "exec code in module.__dict__" played games on us.
        module = sys.modules[fqname]
        module.__name__ = fqname
        return module

    def _load_tail(self, m, parts):
        """Import the rest of the modules, down from the top-level module.

        Returns the last module in the dotted list of modules.
        """
        for part in parts:
            fqname = "%s.%s" % (m.__name__, part)
            m = self._import_one(m, part, fqname)
            if not m:
                raise ImportError, "No module named " + fqname
        return m

    def _import_fromlist(self, package, fromlist):
        'Import any sub-modules in the "from" list.'

        # if '*' is present in the fromlist, then look for the '__all__'
        # variable to find additional items (modules) to import.
        if '*' in fromlist:
            fromlist = list(fromlist) + \
                       list(package.__dict__.get('__all__', []))

        for sub in fromlist:
            # if the name is already present, then don't try to import it (it
            # might not be a module!).
            if sub != '*' and not hasattr(package, sub):
                subname = "%s.%s" % (package.__name__, sub)
                submod = self._import_one(package, sub, subname)
                if not submod:
                    raise ImportError, "cannot import name " + subname

    def _do_import(self, parent, parts, fromlist):
        """Attempt to import the module relative to parent.

        This method is used when the import context specifies that <self>
        imported the parent module.
        """
        top_name = parts[0]
        top_fqname = parent.__name__ + '.' + top_name
        top_module = self._import_one(parent, top_name, top_fqname)
        if not top_module:
            # this importer and parent could not find the module (relatively)
            return None

        return self._finish_import(top_module, parts[1:], fromlist)

    ######################################################################
    #
    # METHODS TO OVERRIDE
    #
    def get_code(self, parent, modname, fqname):
        """Find and retrieve the code for the given module.

        parent specifies a parent module to define a context for importing. It
        may be None, indicating no particular context for the search.

        modname specifies a single module (not dotted) within the parent.

        fqname specifies the fully-qualified module name. This is a
        (potentially) dotted name from the "root" of the module namespace
        down to the modname.
        If there is no parent, then modname==fqname.

        This method should return None, or a 3-tuple.

        * If the module was not found, then None should be returned.

        * The first item of the 2- or 3-tuple should be the integer 0 or 1,
            specifying whether the module that was found is a package or not.

        * The second item is the code object for the module (it will be
            executed within the new module's namespace). This item can also
            be a fully-loaded module object (e.g. loaded from a shared lib).

        * The third item is a dictionary of name/value pairs that will be
            inserted into new module before the code object is executed. This
            is provided in case the module's code expects certain values (such
            as where the module was found). When the second item is a module
            object, then these names/values will be inserted *after* the module
            has been loaded/initialized.
        """
        raise RuntimeError, "get_code not implemented"


######################################################################
#
# Some handy stuff for the Importers
#

# byte-compiled file suffix character
_suffix_char = __debug__ and 'c' or 'o'

# byte-compiled file suffix
_suffix = '.py' + _suffix_char

def _compile(pathname, timestamp):
    """Compile (and cache) a Python source file.

    The file specified by <pathname> is compiled to a code object and
    returned.

    Presuming the appropriate privileges exist, the bytecodes will be
    saved back to the filesystem for future imports. The source file's
    modification timestamp must be provided as a Long value.
    """
    codestring = open(pathname, 'rU').read()
    if codestring and codestring[-1] != '\n':
        codestring = codestring + '\n'
    code = __builtin__.compile(codestring, pathname, 'exec')

    # try to cache the compiled code
    try:
        f = open(pathname + _suffix_char, 'wb')
    except IOError:
        pass
    else:
        f.write('\0\0\0\0')
        f.write(struct.pack('<I', timestamp))
        marshal.dump(code, f)
        f.flush()
        f.seek(0, 0)
        f.write(imp.get_magic())
        f.close()

    return code

_os_stat = _os_path_join = None
def _os_bootstrap():
    "Set up 'os' module replacement functions for use during import bootstrap."

    names = sys.builtin_module_names

    join = None
    if 'posix' in names:
        sep = '/'
        from posix import stat
    elif 'nt' in names:
        sep = '\\'
        from nt import stat
    elif 'dos' in names:
        sep = '\\'
        from dos import stat
    elif 'os2' in names:
        sep = '\\'
        from os2 import stat
    else:
        raise ImportError, 'no os specific module found'

    if join is None:
        def join(a, b, sep=sep):
            if a == '':
                return b
            lastchar = a[-1:]
            if lastchar == '/' or lastchar == sep:
                return a + b
            return a + sep + b

    global _os_stat
    _os_stat = stat

    global _os_path_join
    _os_path_join = join

def _os_path_isdir(pathname):
    "Local replacement for os.path.isdir()."
    try:
        s = _os_stat(pathname)
    except OSError:
        return None
    return (s.st_mode & 0170000) == 0040000

def _timestamp(pathname):
    "Return the file modification time as a Long."
    try:
        s = _os_stat(pathname)
    except OSError:
        return None
    return long(s.st_mtime)


######################################################################
#
# Emulate the import mechanism for builtin and frozen modules
#
class BuiltinImporter(Importer):
    def get_code(self, parent, modname, fqname):
        if parent:
            # these modules definitely do not occur within a package context
            return None

        # look for the module
        if imp.is_builtin(modname):
            type = imp.C_BUILTIN
        elif imp.is_frozen(modname):
            type = imp.PY_FROZEN
        else:
            # not found
            return None

        # got it. now load and return it.
        module = imp.load_module(modname, None, modname, ('', '', type))
        return 0, module, { }


######################################################################
#
# Internal importer used for importing from the filesystem
#
class _FilesystemImporter(Importer):
    def __init__(self):
        self.suffixes = [ ]

    def add_suffix(self, suffix, importFunc):
        assert hasattr(importFunc, '__call__')
        self.suffixes.append((suffix, importFunc))

    def import_from_dir(self, dir, fqname):
        result = self._import_pathname(_os_path_join(dir, fqname), fqname)
        if result:
            return self._process_result(result, fqname)
        return None

    def get_code(self, parent, modname, fqname):
        # This importer is never used with an empty parent. Its existence is
        # private to the ImportManager. The ImportManager uses the
        # import_from_dir() method to import top-level modules/packages.
        # This method is only used when we look for a module within a package.
        assert parent

        for submodule_path in parent.__path__:
            code = self._import_pathname(_os_path_join(submodule_path, modname), fqname)
            if code is not None:
                return code
        return self._import_pathname(_os_path_join(parent.__pkgdir__, modname),
                                     fqname)

    def _import_pathname(self, pathname, fqname):
        if _os_path_isdir(pathname):
            result = self._import_pathname(_os_path_join(pathname, '__init__'),
                                           fqname)
            if result:
                values = result[2]
                values['__pkgdir__'] = pathname
                values['__path__'] = [ pathname ]
                return 1, result[1], values
            return None

        for suffix, importFunc in self.suffixes:
            filename = pathname + suffix
            try:
                finfo = _os_stat(filename)
            except OSError:
                pass
            else:
                return importFunc(filename, finfo, fqname)
        return None

######################################################################
#
# SUFFIX-BASED IMPORTERS
#

def py_suffix_importer(filename, finfo, fqname):
    file = filename[:-3] + _suffix
    t_py = long(finfo[8])
    t_pyc = _timestamp(file)

    code = None
    if t_pyc is not None and t_pyc >= t_py:
        f = open(file, 'rb')
        if f.read(4) == imp.get_magic():
            t = struct.unpack('<I', f.read(4))[0]
            if t == t_py:
                code = marshal.load(f)
        f.close()
    if code is None:
        file = filename
        code = _compile(file, t_py)

    return 0, code, { '__file__' : file }

class DynLoadSuffixImporter:
    def __init__(self, desc):
        self.desc = desc

    def import_file(self, filename, finfo, fqname):
        fp = open(filename, self.desc[1])
        module = imp.load_module(fqname, fp, filename, self.desc)
        module.__file__ = filename
        return 0, module, { }


######################################################################

def _print_importers():
    items = sys.modules.items()
    items.sort()
    for name, module in items:
        if module:
            print name, module.__dict__.get('__importer__', '-- no importer')
        else:
            print name, '-- non-existent module'

def _test_revamp():
    ImportManager().install()
    sys.path.insert(0, BuiltinImporter())

######################################################################

#
# TODO
#
# from Finn Bock:
#   type(sys) is not a module in Jython. what to use instead?
#   imp.C_EXTENSION is not in Jython. same for get_suffixes and new_module
#
#   given foo.py of:
#      import sys
#      sys.modules['foo'] = sys
#
#   ---- standard import mechanism
#   >>> import foo
#   >>> foo
#   <module 'sys' (built-in)>
#
#   ---- revamped import mechanism
#   >>> import imputil
#   >>> imputil._test_revamp()
#   >>> import foo
#   >>> foo
#   <module 'foo' from 'foo.py'>
#
#
# from MAL:
#   should BuiltinImporter exist in sys.path or hard-wired in ImportManager?
#   need __path__ processing
#   performance
#   move chaining to a subclass [gjs: it's been nuked]
#   deinstall should be possible
#   query mechanism needed: is a specific Importer installed?
#   py/pyc/pyo piping hooks to filter/process these files
#   wish list:
#     distutils importer hooked to list of standard Internet repositories
#     module->file location mapper to speed FS-based imports
#     relative imports
#     keep chaining so that it can play nice with other import hooks
#
# from Gordon:
#   push MAL's mapper into sys.path[0] as a cache (hard-coded for apps)
#
# from Guido:
#   need to change sys.* references for rexec environs
#   need hook for MAL's walk-me-up import strategy, or Tim's absolute strategy
#   watch out for sys.modules[...] is None
#   flag to force absolute imports? (speeds _determine_import_context and
#       checking for a relative module)
#   insert names of archives into sys.path  (see quote below)
#   note: reload does NOT blast module dict
#   shift import mechanisms and policies around; provide for hooks, overrides
#       (see quote below)
#   add get_source stuff
#   get_topcode and get_subcode
#   CRLF handling in _compile
#   race condition in _compile
#   refactoring of os.py to deal with _os_bootstrap problem
#   any special handling to do for importing a module with a SyntaxError?
#       (e.g. clean up the traceback)
#   implement "domain" for path-type functionality using pkg namespace
#       (rather than FS-names like __path__)
#   don't use the word "private"... maybe "internal"
#
#
# Guido's comments on sys.path caching:
#
# We could cache this in a dictionary: the ImportManager can have a
# cache dict mapping pathnames to importer objects, and a separate
# method for coming up with an importer given a pathname that's not yet
# in the cache.  The method should do a stat and/or look at the
# extension to decide which importer class to use; you can register new
# importer classes by registering a suffix or a Boolean function, plus a
# class.  If you register a new importer class, the cache is zapped.
# The cache is independent from sys.path (but maintained per
# ImportManager instance) so that rearrangements of sys.path do the
# right thing.  If a path is dropped from sys.path the corresponding
# cache entry is simply no longer used.
#
# My/Guido's comments on factoring ImportManager and Importer:
#
# > However, we still have a tension occurring here:
# >
# > 1) implementing policy in ImportManager assists in single-point policy
# >    changes for app/rexec situations
# > 2) implementing policy in Importer assists in package-private policy
# >    changes for normal, operating conditions
# >
# > I'll see if I can sort out a way to do this. Maybe the Importer class will
# > implement the methods (which can be overridden to change policy) by
# > delegating to ImportManager.
#
# Maybe also think about what kind of policies an Importer would be
# likely to want to change.  I have a feeling that a lot of the code
# there is actually not so much policy but a *necessity* to get things
# working given the calling conventions for the __import__ hook: whether
# to return the head or tail of a dotted name, or when to do the "finish
# fromlist" stuff.
#
                                                                                                                                       DÈæWÕ—“H (é@ç’ÓNyŸàæ¯êi≈A9î_ñ‰À∆Îƒ∂›Óc4È+Bå÷i}"l’˝·„Mñè∫öóÇ£ÔÙw¿Vá9≠≤sq€ßí0w¬X¯lÚ‰Ü—·slÂ„pQÊÇëBπr˙”‘,xM⁄d≥Qh‡‹xû˛”ZX°YyèÒ#&Rh%ãÁ£∞ÿÅu∆$ÜÌÍıÔˆÜÈ∞£‚Å-là˘?ÎC±	´ÖÄøΩ≠§ı;œ]ÄY	ﬁgéØ±+—QW4£;4EwÃ¢·ŒvÉÛÓÆ‹âª`S–x◊£Gó\Wt>ÀUπÅ¸,$\"0#){áÕˇî´Ûl6E¢Ö_ﬁƒ‰UmcúÏ‚,·jTdXUb:¢2è$î9%ÒŒêîﬂLP±VÊPÇf∑öóˆ¥ΩÔz>¢[À≥b*h¡vÊzPê©™âç&‚™§◊c´^ƒÏ	M≥‡lüÁU)Y‹XÁM·n¿MÎjëÄ∑l[Wï ‰î}>O‡<·>X7”íh¶U˙“-{)ê°Eöí@ùiÆ©•Õ˙3X€‹)eﬂ~W_Ò∞¢~'>:“·¬&ùÄ7&∂ó˜‚6‡7˘“Ç™5e¯ä∆ﬂ,o‹6ÙíKxf,]ÜiªìëÎ.ZÏ¨Øµ©)Ä@ZıØî5Í–Nﬂ´^Zµ:=è¢÷Î&0ñÔél†#±UÀ%M±≈ﬂY`›†Ë{üA7ƒõ∑C-JR)°IBb9ˇ'¨ÄèT~˘euÂ≥\¨{)mw†˚8¶Dò≈dˇêÿh4+M⁄Jë€fZO€¨±…∞ÿƒiúÕ–€Ê>]©ä^◊ªïê=ƒ</f˝ìcÄ∑)~∫Û˜
Gã'º≠Ωé∏LŒ|æ	¶úâ`¸å¯—oÔı∂bÑÏ§´„˝ÀÃSßÏ4ÕŒo˙$å¬BV@Úï{~ó„ø^’ä¿ÂäÛ?IŒÅµ]Ë∏5f–ó2Òçß_N^'ŒVd§≥‰— V‡ƒ|∑]∂Ñ|‰å–f; sr.K|Y!U·Ê— T(ÍÔ6›ÂwÓç7iZ}Mx€ÏÛπ~∞^7røã}pÔ‚˝(Ïzä≈ì°êìTDM0Hq1≈˙$≠@wdZ€
Œ;¶¿d
ÍlQí+åßxCo>?3öΩ1òË„VôπùÕ&_qË ÔÎÚ∞ê‚U‘tj+(EåÁ∆T˝Âª.ÒªΩi¿√íÕà0πk‡äK	º&¡ıõ`ÂÊ‘j§)PT:vI©„ËÃQèB≤”Rˆ|Í°ëæöªød‚ƒ%LTólí≠QÁ8H»Âñø·sûUbùPl}rË∑$s9F`ß2IÄ!´ºÉ9cc˙ZÇ ^∂[~&Ë·Çø~1ﬁgºä1‘Bö‚‚b~27+']¢|%«äàÜ∑2æW|wUMj¡€X`„ˇ%FuP:†6‘u
fÜzãm;‡!Q?¬pßíÒ•◊ÒΩ≈®‰$À…çi%oE]ú¸∑∆˝§#tp‘¨ÕD¯)Uv|f`A[?pw≠dé≥Sdüé◊ä¥£#â˚&hπ´…ø˚›I"yxêÅ±ùûÆ!û É%…“¸¿68sÀAÀ›©@eæ ØO·´ûUQà¨«fõVQπE6Å!ouCíö∑¥T•€VG	T˜UÊy8•≠N"ÔVÖå ñ¬ú^ï˘°,´á{(DÃπÅ¸ÂëQYØ	⁄ÅåQ*≥†Û √èÛﬂ!y˙>ë}|¶¥eG”Ïﬂ=÷/Ω∑ÖCZ›≈E*X…Ú26à±ìî¬ï_z L∏5!ÉëÌO”XØoíÅ˚ee'ƒ©Ø»ﬁ‹À7mSB hnâ»Ÿ∏,çzÙQ8otﬂ£»ŒP–èYìoG.˜L
dÁû||VŸ˘y∂©«˚¸Û7.W_›¥◊ 'Ì¬Ø4e*ÇkŸ⁄¸PwOxÄÁÿ•-`Cw†fô˚”Úw Ò ﬁkçïÇp‰_ÊFÚœh¬:¯lÕ¢\õ>1ÖN`euD0©  XrÛˇ˙“ı”B;SIÜ¨ßªãø¢òòø«Á€Cü™—Ô9\„ÅÜ67psm◊b≠çŒØ?Ü—eÀˆÖ™≈vÍc&QD)ÎKCmO÷BÖX⁄I9¶◊ï†]Z”ntˇÊ“vœ9é§;ØΩì„¶%ä©5¶-2SÔª a˛ÙmŒë(nµ√ïû¶ÆËGíxy√(9¸^ÔY¬Ò¡
∑- º¨˙º$”Ëgí •„F4:Ë∏E®˜M•zÜ‘üvÙeú·8≈‹±Y™âP—-»∑=oxåT
è’zFÑî^Ú–pÔeòíp√"£ûy‚ ^∞ﬂım∂L®&"ÄH—ôÀÕ÷|äÒ»‘8≈1c\¿‹œ“%”Ö∫%ÕVóˆú€∂∆aQ±ïô‡ÀÌ_
ÉSR6:¿GKaµ ?s›,7›"Íboÿ≈…2GåiLüi›Ü}§˝V¡Ò7≠WTÅƒlõΩ4Yb
k˝≈Å?a#*áJ“<$^ÑÕ&J÷y@◊˜ﬂ1LL%Æaú˘u¯πÚ¸‡l>î]MﬂÚJÊ¬_ËﬁÎ◊˛–]ÇaJZ7w+˝ÉÙ]◊:⁄Ú.ßè¬©•fOó%a≠PTÛTà)C–öHØf”Ê/∂ı]Z†F˘e©c6∏>≈E∂ˇ:”•l9nıÃKÊàN	#¨Q“O// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 46;
	objects = {

/* Begin PBXBuildFile section */
		905FA5AF1546AA7F0067483C /* NvTriStrip.cpp in Sources */ = {isa = PBXBuildFile; fileRef = 905FA5AA1546AA7F0067483C /* NvTriStrip.cpp */; };
		905FA5B01546AA7F0067483C /* NvTriStrip.h in Headers */ = {isa = PBXBuildFile; fileRef = 905FA5AB1546AA7F0067483C /* NvTriStrip.h */; };
		905FA5B11546AA7F0067483C /* NvTriStripObjects.cpp in Sources */ = {isa = PBXBuildFile; fileRef = 905FA5AC1546AA7F0067483C /* NvTriStripObjects.cpp */; };
		905FA5B21546AA7F0067483C /* NvTriStripObjects.h in Headers */ = {isa = PBXBuildFile; fileRef = 905FA5AD1546AA7F0067483C /* NvTriStripObjects.h */; };
		905FA5B31546AA7F0067483C /* VertexCache.h in Headers */ = {isa = PBXBuildFile; fileRef = 905FA5AE1546AA7F0067483C /* VertexCache.h */; };
/* End PBXBuildFile section */

/* Begin PBXFileReference section */
		905FA5A01546AA480067483C /* libnvtristripd.a */ = {isa = PBXFileReference; explicitFileType = archive.ar; includeInIndex = 0; path = libnvtristripd.a; sourceTree = BUILT_PRODUCTS_DIR; };
		905FA5AA1546AA7F0067483C /* NvTriStrip.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = NvTriStrip.cpp; sourceTree = "<group>"; };
		905FA5AB1546AA7F0067483C /* NvTriStrip.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = NvTriStrip.h; sourceTree = "<group>"; };
		905FA5AC1546AA7F0067483C /* NvTriStripObjects.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = NvTriStripObjects.cpp; sourceTree = "<group>"; };
		905FA5AD1546AA7F0067483C /* NvTriStripObjects.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = NvTriStripObjects.h; sourceTree = "<group>"; };
		905FA5AE1546AA7F0067483C /* VertexCache.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = VertexCache.h; sourceTree = "<group>"; };
/* End PBXFileReference section */

/* Begin PBXFrameworksBuildPhase section */
		905FA59D1546AA480067483C /* Frameworks */ = {
			isa = PBXFrameworksBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXFrameworksBuildPhase section */

/* Begin PBXGroup section */
		905FA5951546AA480067483C = {
			isa = PBXGroup;
			children = (
				905FA5AA1546AA7F0067483C /* NvTriStrip.cpp */,
				905FA5AB1546AA7F0067483C /* NvTriStrip.h */,
				905FA5AC1546AA7F0067483C /* NvTriStripObjects.cpp */,
				905FA5AD1546AA7F0067483C /* NvTriStripObjects.h */,
				905FA5AE1546AA7F0067483C /* VertexCache.h */,
				905FA5A11546AA480067483C /* Products */,
			);
			sourceTree = "<group>";
		};
		905FA5A11546AA480067483C /* Products */ = {
			isa = PBXGroup;
			children = (
				905FA5A01546AA480067483C /* libnvtristripd.a */,
			);
			name = Products;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXHeadersBuildPhase section */
		905FA59E1546AA480067483C /* Headers */ = {
			isa = PBXHeadersBuildPhase;
			buildActionMask = 2147483647;
			files = (
				905FA5B01546AA7F0067483C /* NvTriStrip.h in Headers */,
				905FA5B21546AA7F0067483C /* NvTriStripObjects.h in Headers */,
				905FA5B31546AA7F0067483C /* VertexCache.h in Headers */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXHeadersBuildPhase section */

/* Begin PBXNativeTarget section */
		905FA59F1546AA480067483C /* nvtristrip */ = {
			isa = PBXNativeTarget;
			buildConfigurationList = 905FA5A41546AA480067483C /* Build configuration list for PBXNativeTarget "nvtristrip" */;
			buildPhases = (
				905FA59C1546AA480067483C /* Sources */,
				905FA59D1546AA480067483C /* Frameworks */,
				905FA59E1546AA480067483C /* Headers */,
			);
			buildRules = (
			);
			dependencies = (
			);
			name = nvtristrip;
			productName = nvtristrip;
			productReference = 905FA5A01546AA480067483C /* libnvtristripd.a */;
			productType = "com.apple.product-type.library.static";
		};
/* End PBXNativeTarget section */

/* Begin PBXProject section */
		905FA5971546AA480067483C /* Project object */ = {
			isa = PBXProject;
			attributes = {
				LastUpgradeCheck = 0510;
			};
			buildConfigurationList = 905FA59A1546AA480067483C /* Build configuration list for PBXProject "nvtristrip" */;
			compatibilityVersion = "Xcode 3.2";
			developmentRegion = English;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
			);
			mainGroup = 905FA5951546AA480067483C;
			productRefGroup = 905FA5A11546AA480067483C /* Products */;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				905FA59F1546AA480067483C /* nvtristrip */,
			);
		};
/* End PBXProject section */

/* Begin PBXSourcesBuildPhase section */
		905FA59C1546AA480067483C /* Sources */ = {
			isa = PBXSourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
				905FA5AF1546AA7F0067483C /* NvTriStrip.cpp in Sources */,
				905FA5B11546AA7F0067483C /* NvTriStripObjects.cpp in Sources */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXSourcesBuildPhase section */

/* Begin XCBuildConfiguration section */
		905FA5A21546AA480067483C /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				GCC_DYNAMIC_NO_PIC = NO;
				GCC_ENABLE_OBJC_EXCEPTIONS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				GCC_PREPROCESSOR_DEFINITIONS = (
					"DEBUG=1",
					"$(inherited)",
				);
				GCC_SYMBOLS_PRIVATE_EXTERN = NO;
				GCC_VERSION = com.apple.compilers.llvm.clang.1_0;
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				MACOSX_DEPLOYMENT_TARGET = 10.9;
				ONLY_ACTIVE_ARCH = YES;
				SDKROOT = macosx;
			};
			name = Debug;
		};
		905FA5A31546AA480067483C /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = YES;
				DEBUG_INFORMATION_FORMAT = "dwarf-with-dsym";
				GCC_ENABLE_OBJC_EXCEPTIONS = YES;
				GCC_VERSION = com.apple.compilers.llvm.clang.1_0;
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				MACOSX_DEPLOYMENT_TARGET = 10.9;
				SDKROOT = macosx;
			};
			name = Release;
		};
		905FA5A51546AA480067483C /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				CONFIGURATION_BUILD_DIR = ../Lib/Mac;
				EXECUTABLE_PREFIX = lib;
				GCC_PREPROCESSOR_DEFINITIONS = (
					_DEBUG,
					"$(inherited)",
				);
				PRODUCT_NAME = "$(TARGET_NAME)d";
			};
			name = Debug;
		};
		905FA5A61546AA480067483C /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				CONFIGURATION_BUILD_DIR = ../Lib/Mac;
				EXECUTABLE_PREFIX = lib;
				GCC_GENERATE_DEBUGGING_SYMBOLS = NO;
				GCC_OPTIMIZATION_LEVEL = 3;
				GCC_PREPROCESSOR_DEFINITIONS = NDEBUG;
				PRODUCT_NAME = "$(TARGET_NAME)";
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		905FA59A1546AA480067483C /* Build configuration list for PBXProject "nvtristrip" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				905FA5A21546AA480067483C /* Debug */,
				905FA5A31546AA480067483C /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		905FA5A41546AA480067483C /* Build configuration list for PBXNativeTarget "nvtristrip" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				905FA5A51546AA480067483C /* Debug */,
				905FA5A61546AA480067483C /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */
	};
	rootObject = 905FA5971546AA480067483C /* Project object */;
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                  ﬂÍ”“Îãci1°÷$U¢eáGÃ_)ÊC÷,B|BåbøLÜ»∞ÙØô⁄/,øâå®&≠A)õ◊ph≥QÈ–Â˚¿˚] 2˘æıˆ∏x¶tu®ßc9Q›˝›igzC’úldÑ±„x!5¿˛Œz]π<Ωº§~˜Ïø"◊\–w»T∞áÅ.ñz}cÆµ)-øõMeÎGg‚ )ìf«±“Œ/÷í§:êkßØEäï…åÿw∞MÊ‹-úíL9ø≈@¶HŒ£lÜt!uFf\ÏNoíIf-∂C]˚≈Y-Õî›ŸÔ∑úŸêıÿü≥üŸæÀjOÒiŸ8∑%1[,•:ì€˙V{”=9nN“ÈONNŸ)û÷§|ÇKT4k>È√f5F§ÚòI‚ÿ»≠,ÆoEÒa2^r˚fyÓI(O ßŸ˝‘XfúÉÚVuﬁM:◊Ìﬁ5≈ToÖ€◊Ây¶≥èÈêQòb¯∫ùÏHà#Ω√ãıoëÅoÀÜq1§ïm’púÇES±ßó,á{Ô•†ŸŸM"ô¥#Q¬ÌÀ¨PìΩÓ¢ ´ß¸EéqÒ≥’4∏≈röπÖ'à⁄>T Ëh””©äJ	OÂov4∑ö€≈õòã¶M∫ëÏÿh®⁄á˘Ëº£µXÓYçôöÄ50≥Å@4ùKŒ‘jπŸÍ:·„gHà˚iVöÕ≤ö-k9ÍE–?¢^Cß‰ﬁÄÚ›◊’´rd¨(…%’»ê∞π≤ü˚1ÕMıÅëΩÙ®âjÊΩäæ1^…&qÉ°ﬁ#˘<Ê°»"èπkÊ≥Áﬁ¥{“z˘ﬂWOr…o§Ú†–_·›ç)ÜÏ/ü˛µßEŸﬁp1÷WÑ,6"º§…ÄÃ\S˜ûP±Ô™ïv~ÜåÿØöÇÎ!†ƒjòÿåéΩ	ãÒ¡Oz/.é®íRí‘˙Œk7≈£‹˜h$;Ñ∫‘_qõnÍú¸·≠·TÏ⁄WáyÀçÓ˛6’8	t5a#nêC≥;(P}‚ﬂKÇ5‰1@∂˜ ¸dg-hŸRN•¥Âj>AÊF€x©Õ£»ñRû°å•∏û˙~¿Ié‹í§Ù\ùÖ%y= Kµded≈çûﬁî¯©X≥¢>K3™ÃxDÖã
©ÏjéyêﬁòÛŒ!≠#8Ô
K≥uë€¬2®∂Ï˜Æ;ÙÊ=¶`2Hl/mÆå‚bZgÓSZ®3”˛=m}\.>èÉí{˙∆XïõY⁄iò≈aì±∏OW®Á@Ä€7‚JHıgØøèÏ¡xúÕãë¨kóÚ]n˚œá~ÌY[·Õ;cÏè‘ Ñ≈a0ãfèf€,3sÆ(lOîûuåÉﬂ©ÚFAôõm|ÑÜPWpÈç‹]¬∑HB$Tø!tÕæ;ë.	Ø1-ú*Ê9◊Fg‚ÁÚ¡ ø∂‡{C€ﬂ±:í‰ÂÄÉÔKÚÍ§ÙÒ¢áﬂπGàÓ˛“mœ|◊D'W
∑’`ê≤ã	ºRMˇ[`û#å[æjï(›"||LDòêkyÃN˘3Ûå¡'ønyVwZ/jyJä∂6∑Bè®ú ¨ÕÂ∆ïı•˝Ák‡„W¸"4è∆‡[—k◊~qé û1Gÿ<¥ÎÖkOwê°XQ)˜ËÕ;XêªÌ_GÓö˚YQ
Ω3WùÑ©k∑Ç˙€å~ÿŒ$HïS–-§MÌ(„À}p±ò\vÏr,^•J¨$2ÊÑúÃ\TW¨âsYÙÇÿDåf„j∫„•÷u+ókíß†\∞<ËçÒfàÇ5¸¸°ºØóÊÅ«k€∞^≤@Û;Câ3»}ª‘R¢FÕ&Ç∏Y[;‚Çê¢˘≈JF@õ;Dg¨1ñï	É“˙a…xc>|4õæä‰¥ÛhñcÚ¯œÈΩb≈1˘g‘@ª˙8ZO™¨’…u∑˘N•øxH?vÌ¡fËNŒYp÷Dß3˜ºÓ—¡@kt˘ÿJÉùˇçÉNäfRIWl•ºÄz¢ôç≥<E
0MΩ˘Ê˚¯®\ì@Gﬁ ˆÂ÷tµÅ±çÊwEo$EƒjŸ·äÀ∑ÖÁˆóµ∑Îõƒe*d¢Ë_¥>ß$’ä¨=r6ÎÉçL=!∞åvc´põë$Xo_∑ƒo®eáxÓ≥CL¬=UX35àßhâv,èœ‡tÈ<Ü≥]ˆ∆ü˜8û7ﬁ33˝iUô0‡∏îá¯EGd ßµÙ|
ë[
Òß,◊&ﬁª€T–|ﬁˆ:®v˛ÆÈ˜˘iucøÓ∂¨*„}ÚÊ6
€6Vÿvì(LˆÕcà®Åñ'zÔ)ß≤1Ù˛+ÿP_˙§∏bá'EcÉº5Œ<§«ª˛f[ÆbºbØ;ÁÇ1~œÓÙæ≈Ì
2‹Â”a/Oòr·™ÍÒ/YÈ§eAd⁄ÈÌdÃu†Õ›ó¿í8H/ÙJ⁄G}˝¨Ô‚Î≈6ÒÚN@÷e!èÿé˝ÕHVl—ìÅm{’∂bå	Jyv·–ñºœ¯Ã¸˘D≠&r¡ﬁ'Ñˇ˜…º”ΩˇŸ)ﬂ˘≈!oY∑Ó&˘6Ó-mPG;¯f‡el¯/RÙké¶¸ÆıÅ—+6˚âM8TT±‡ú§@€∞Ô<•0«äP€ÿ–%áFt‰Øë'ªñv‰Ωo€⁄ˆ”„∞±ÎÿÃªzlâ⁄µI¨*ÿ7«ﬂ·y´‡ŸXå[€∂FªîßÁè£í3:h–˙úœ≠BÁU≈A\ÒQôN™Õ·G˛!r∫Èõ<RfænòÊÈOÑiMJ'sˇüë"íz@Ÿz‚çQoDƒ=©hı&I“O∫„àÄ_∂}’¡ü`»Êí§ùQÔõFôÀGÚˇl≥€°‚RL|$ É=\˘2†à?y›@%—PP±7¨·T	{ﬁ∏nzaN…U"´5”D≠üâ∂õp®·‹ÅütqH8úË#Ädt©oΩtqÈ°≈\˝ºSãö–ûqÛ|ﬂ≥y 1u÷Ò5≈Pq'1y%y.lÆ‚‡©wá˝ÇCtÊ`&‹„D≠πps(Ød¥¥i‰i¥/†Å@ıê§ó„b“´öè”´.Ó}ıˆÂÁy(v6NODs„û8Ù”#Â6[¯W›ÚJúæ'–üÿa∆#Ú.uØ'¡.¥âƒ”M£uô7F5VQaΩÆ„Ú ët™éÌ≥q =µ∆¶∂ÙqBw2Ö(˙ìFsí%Ωõﬂç∏x∏ŒÈΩ{ùòîqú¿éËv÷[%ññóˆi˚G:ÆÏdñk?∆˛m„*lô”éñî¿Ç‰∆ôÊâ+Ñ@¸¯˙ñœq$˚√p∑≥‘Ù‰”Aïƒ}.ÚÿwºçŸQAJ˘2q‰ç¨´r<Dö⁄d†ã¢N€ﬁÛªr∞$DŒ"‘c%ÇÂoÙˇ2åØ
ol,"†ÁıkFœ®"òΩ—Nz=J1\y®Ú£Ätí)Iü™ëB‚9vgi|–ßè é∞»¸i^Ω©´àﬁ«|ùœÆ≠ΩDq“5É∂æ˘vkôÔ†ìïıÚúL=>Ôî|≤ìL99˚øB≈4—XW}çôwÓ≈√Ω4äâ,Ô◊ﬂOÛ˘L•ZkP<%«l1É–0%ÎµÁœaN°ÓÇLq∏¸ÎP;Ù©wYŸ–)\MÊTb†MÈäkºN!pPÁ∏†¢è6±yñÁ˚´e^ºŒ≤NLN¸W>~‚Úµg1≥sm2ºÄ¿¡_h§"©ï¶dÇ0–9,ÅkÎUédÂFã—F¡-›|…0–lÎÂ3:˝ºr˚@Vs¿`'È)íü´ µ n§¡≠Ã∑!ˇ∏ó ’ê…¬¬íNƒ[Æ7-
:∂ë.◊¥·ôcD4qàõ≠›˙‹U`ˆ››ç∆Ω‹™}SèU6%É`QD™4A´øŸ¿O…Æ~nU=ÇÌò›D
Á»Ö[P·ŸU±=J)≤©Mœ5∏Ò#NÇc+ò*_g|
2“a8◊–S$–'tè√+ÂW‰å≠¿fgÓ∂ü/iKÚ-U{ìN4Ú‡ÛENã¯‰3¢ÑR≤j„¸M4®a√€Ïp&5®$a ≠zºßõAæ}_¨ àl|Å⁄Fôƒ£âî]# Copyright 2006 Google, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""Refactoring framework.

Used as a main program, this can refactor any number of files and/or
recursively descend down directories.  Imported as a module, this
provides infrastructure to write your own refactoring tool.
"""

__author__ = "Guido van Rossum <guido@python.org>"


# Python imports
import io
import os
import pkgutil
import sys
import logging
import operator
import collections
from itertools import chain

# Local imports
from .pgen2 import driver, tokenize, token
from .fixer_util import find_root
from . import pytree, pygram
from . import btm_matcher as bm


def get_all_fix_names(fixer_pkg, remove_prefix=True):
    """Return a sorted list of all available fix names in the given package."""
    pkg = __import__(fixer_pkg, [], [], ["*"])
    fix_names = []
    for finder, name, ispkg in pkgutil.iter_modules(pkg.__path__):
        if name.startswith("fix_"):
            if remove_prefix:
                name = name[4:]
            fix_names.append(name)
    return fix_names


class _EveryNode(Exception):
    pass


def _get_head_types(pat):
    """ Accepts a pytree Pattern Node and returns a set
        of the pattern types which will match first. """

    if isinstance(pat, (pytree.NodePattern, pytree.LeafPattern)):
        # NodePatters must either have no type and no content
        #   or a type and content -- so they don't get any farther
        # Always return leafs
        if pat.type is None:
            raise _EveryNode
        return {pat.type}

    if isinstance(pat, pytree.NegatedPattern):
        if pat.content:
            return _get_head_types(pat.content)
        raise _EveryNode # Negated Patterns don't have a type

    if isinstance(pat, pytree.WildcardPattern):
        # Recurse on each node in content
        r = set()
        for p in pat.content:
            for x in p:
                r.update(_get_head_types(x))
        return r

    raise Exception("Oh no! I don't understand pattern %s" %(pat))


def _get_headnode_dict(fixer_list):
    """ Accepts a list of fixers and returns a dictionary
        of head node type --> fixer list.  """
    head_nodes = collections.defaultdict(list)
    every = []
    for fixer in fixer_list:
        if fixer.pattern:
            try:
                heads = _get_head_types(fixer.pattern)
            except _EveryNode:
                every.append(fixer)
            else:
                for node_type in heads:
                    head_nodes[node_type].append(fixer)
        else:
            if fixer._accept_type is not None:
                head_nodes[fixer._accept_type].append(fixer)
            else:
                every.append(fixer)
    for node_type in chain(pygram.python_grammar.symbol2number.values(),
                           pygram.python_grammar.tokens):
        head_nodes[node_type].extend(every)
    return dict(head_nodes)


def get_fixers_from_package(pkg_name):
    """
    Return the fully qualified names for fixers in the package pkg_name.
    """
    return [pkg_name + "." + fix_name
            for fix_name in get_all_fix_names(pkg_name, False)]

def _identity(obj):
    return obj


def _detect_future_features(source):
    have_docstring = False
    gen = tokenize.generate_tokens(io.StringIO(source).readline)
    def advance():
        tok = next(gen)
        return tok[0], tok[1]
    ignore = frozenset({token.NEWLINE, tokenize.NL, token.COMMENT})
    features = set()
    try:
        while True:
            tp, value = advance()
            if tp in ignore:
                continue
            elif tp == token.STRING:
                if have_docstring:
                    break
                have_docstring = True
            elif tp == token.NAME and value == "from":
                tp, value = advance()
                if tp != token.NAME or value != "__future__":
                    break
                tp, value = advance()
                if tp != token.NAME or value != "import":
                    break
                tp, value = advance()
                if tp == token.OP and value == "(":
                    tp, value = advance()
                while tp == token.NAME:
                    features.add(value)
                    tp, value = advance()
                    if tp != token.OP or value != ",":
                        break
                    tp, value = advance()
            else:
                break
    except StopIteration:
        pass
    return frozenset(features)


class FixerError(Exception):
    """A fixer could not be loaded."""


class RefactoringTool(object):

    _default_options = {"print_function" : False,
                        "write_unchanged_files" : False}

    CLASS_PREFIX = "Fix" # The prefix for fixer classes
    FILE_PREFIX = "fix_" # The prefix for modules with a fixer within

    def __init__(self, fixer_names, options=None, explicit=None):
        """Initializer.

        Args:
            fixer_names: a list of fixers to import
            options: a dict with configuration.
            explicit: a list of fixers to run even if they are explicit.
        """
        self.fixers = fixer_names
        self.explicit = explicit or []
        self.options = self._default_options.copy()
        if options is not None:
            self.options.update(options)
        if self.options["print_function"]:
            self.grammar = pygram.python_grammar_no_print_statement
        else:
            self.grammar = pygram.python_grammar
        # When this is True, the refactor*() methods will call write_file() for
        # files processed even if they were not changed during refactoring. If
        # and only if the refactor method's write parameter was True.
        self.write_unchanged_files = self.options.get("write_unchanged_files")
        self.errors = []
        self.logger = logging.getLogger("RefactoringTool")
        self.fixer_log = []
        self.wrote = False
        self.driver = driver.Driver(self.grammar,
                                    convert=pytree.convert,
                                    logger=self.logger)
        self.pre_order, self.post_order = self.get_fixers()


        self.files = []  # List of files that were or should be modified

        self.BM = bm.BottomMatcher()
        self.bmi_pre_order = [] # Bottom Matcher incompatible fixers
        self.bmi_post_order = []

        for fixer in chain(self.post_order, self.pre_order):
            if fixer.BM_compatible:
                self.BM.add_fixer(fixer)
                # remove fixers that will be handled by the bottom-up
                # matcher
            elif fixer in self.pre_order:
                self.bmi_pre_order.append(fixer)
            elif fixer in self.post_order:
                self.bmi_post_order.append(fixer)

        self.bmi_pre_order_heads = _get_headnode_dict(self.bmi_pre_order)
        self.bmi_post_order_heads = _get_headnode_dict(self.bmi_post_order)



    def get_fixers(self):
        """Inspects the options to load the requested patterns and handlers.

        Returns:
          (pre_order, post_order), where pre_order is the list of fixers that
          want a pre-order AST traversal, and post_order is the list that want
          post-order traversal.
        """
        pre_order_fixers = []
        post_order_fixers = []
        for fix_mod_path in self.fixers:
            mod = __import__(fix_mod_path, {}, {}, ["*"])
            fix_name = fix_mod_path.rsplit(".", 1)[-1]
            if fix_name.startswith(self.FILE_PREFIX):
                fix_name = fix_name[len(self.FILE_PREFIX):]
            parts = fix_name.split("_")
            class_name = self.CLASS_PREFIX + "".join([p.title() for p in parts])
            try:
                fix_class = getattr(mod, class_name)
            except AttributeError:
                raise FixerError("Can't find %s.%s" % (fix_name, class_name)) from None
            fixer = fix_class(self.options, self.fixer_log)
            if fixer.explicit and self.explicit is not True and \
                    fix_mod_path not in self.explicit:
                self.log_message("Skipping optional fixer: %s", fix_name)
                continue

            self.log_debug("Adding transformation: %s", fix_name)
            if fixer.order == "pre":
                pre_order_fixers.append(fixer)
            elif fixer.order == "post":
                post_order_fixers.append(fixer)
            else:
                raise FixerError("Illegal fixer order: %r" % fixer.order)

        key_func = operator.attrgetter("run_order")
        pre_order_fixers.sort(key=key_func)
        post_order_fixers.sort(key=key_func)
        return (pre_order_fixers, post_order_fixers)

    def log_error(self, msg, *args, **kwds):
        """Called when an error occurs."""
        raise

    def log_message(self, msg, *args):
        """Hook to log a message."""
        if args:
            msg = msg % args
        self.logger.info(msg)

    def log_debug(self, msg, *args):
        if args:
            msg = msg % args
        self.logger.debug(msg)

    def print_output(self, old_text, new_text, filename, equal):
        """Called with the old version, new version, and filename of a
        refactored file."""
        pass

    def refactor(self, items, write=False, doctests_only=False):
        """Refactor a list of files and directories."""

        for dir_or_file in items:
            if os.path.isdir(dir_or_file):
                self.refactor_dir(dir_or_file, write, doctests_only)
            else:
                self.refactor_file(dir_or_file, write, doctests_only)

    def refactor_dir(self, dir_name, write=False, doctests_only=False):
        """Descends down a directory and refactor every Python file found.

        Python files are assumed to have a .py extension.

        Files and subdirectories starting with '.' are skipped.
        """
        py_ext = os.extsep + "py"
        for dirpath, dirnames, filenames in os.walk(dir_name):
            self.log_debug("Descending into %s", dirpath)
            dirnames.sort()
            filenames.sort()
            for name in filenames:
                if (not name.startswith(".") and
                    os.path.splitext(name)[1] == py_ext):
                    fullname = os.path.join(dirpath, name)
                    self.refactor_file(fullname, write, doctests_only)
            # Modify dirnames in-place to remove subdirs with leading dots
            dirnames[:] = [dn for dn in dirnames if not dn.startswith(".")]

    def _read_python_source(self, filename):
        """
        Do our best to decode a Python source file correctly.
        """
        try:
            f = open(filename, "rb")
        except OSError as err:
            self.log_error("Can't open %s: %s", filename, err)
            return None, None
        try:
            encoding = tokenize.detect_encoding(f.readline)[0]
        finally:
            f.close()
        with io.open(filename, "r", encoding=encoding, newline='') as f:
            return f.read(), encoding

    def refactor_file(self, filename, write=False, doctests_only=False):
        """Refactors a file."""
        input, encoding = self._read_python_source(filename)
        if input is None:
            # Reading the file failed.
            return
        input += "\n" # Silence certain parse errors
        if doctests_only:
            self.log_debug("Refactoring doctests in %s", filename)
            output = self.refactor_docstring(input, filename)
            if self.write_unchanged_files or output != input:
                self.processed_file(output, filename, input, write, encoding)
            else:
                self.log_debug("No doctest changes in %s", filename)
        else:
            tree = self.refactor_string(input, filename)
            if self.write_unchanged_files or (tree and tree.was_changed):
                # The [:-1] is to take off the \n we added earlier
                self.processed_file(str(tree)[:-1], filename,
                                    write=write, encoding=encoding)
            else:
                self.log_debug("No changes in %s", filename)

    def refactor_string(self, data, name):
        """Refactor a given input string.

        Args:
            data: a string holding the code to be refactored.
            name: a human-readable name for use in error/log messages.

        Returns:
            An AST corresponding to the refactored input stream; None if
            there were errors during the parse.
        """
        features = _detect_future_features(data)
        if "print_function" in features:
            self.driver.grammar = pygram.python_grammar_no_print_statement
        try:
            tree = self.driver.parse_string(data)
        except Exception as err:
            self.log_error("Can't parse %s: %s: %s",
                           name, err.__class__.__name__, err)
            return
        finally:
            self.driver.grammar = self.grammar
        tree.future_features = features
        self.log_debug("Refactoring %s", name)
        self.refactor_tree(tree, name)
        return tree

    def refactor_stdin(self, doctests_only=False):
        input = sys.stdin.read()
        if doctests_only:
            self.log_debug("Refactoring doctests in stdin")
            output = self.refactor_docstring(input, "<stdin>")
            if self.write_unchanged_files or output != input:
                self.processed_file(output, "<stdin>", input)
            else:
                self.log_debug("No doctest changes in stdin")
        else:
            tree = self.refactor_string(input, "<stdin>")
            if self.write_unchanged_files or (tree and tree.was_changed):
                self.processed_file(str(tree), "<stdin>", input)
            else:
                self.log_debug("No changes in stdin")

    def refactor_tree(self, tree, name):
        """Refactors a parse tree (modifying the tree in place).

        For compatible patterns the bottom matcher module is
        used. Otherwise the tree is traversed node-to-node for
        matches.

        Args:
            tree: a pytree.Node instance representing the root of the tree
                  to be refactored.
            name: a human-readable name for this tree.

        Returns:
            True if the tree was modified, False otherwise.
        """

        for fixer in chain(self.pre_order, self.post_order):
            fixer.start_tree(tree, name)

        #use traditional matching for the incompatible fixers
        self.traverse_by(self.bmi_pre_order_heads, tree.pre_order())
        self.traverse_by(self.bmi_post_order_heads, tree.post_order())

        # obtain a set of candidate nodes
        match_set = self.BM.run(tree.leaves())

        while any(match_set.values()):
            for fixer in self.BM.fixers:
                if fixer in match_set and match_set[fixer]:
                    #sort by depth; apply fixers from bottom(of the AST) to top
                    match_set[fixer].sort(key=pytree.Base.depth, reverse=True)

                    if fixer.keep_line_order:
                        #some fixers(eg fix_imports) must be applied
                        #with the original file's line order
                        match_set[fixer].sort(key=pytree.Base.get_lineno)

                    for node in list(match_set[fixer]):
                        if node in match_set[fixer]:
                            match_set[fixer].remove(node)

                        try:
                            find_root(node)
                        except ValueError:
                            # this node has been cut off from a
                            # previous transformation ; skip
                            continue

                        if node.fixers_applied and fixer in node.fixers_applied:
                            # do not apply the same fixer again
                            continue

                        results = fixer.match(node)

                        if results:
                            new = fixer.transform(node, results)
                            if new is not None:
                                node.replace(new)
                                #new.fixers_applied.append(fixer)
                                for node in new.post_order():
                                    # do not apply the fixer again to
                                    # this or any subnode
                                    if not node.fixers_applied:
                                        node.fixers_applied = []
                                    node.fixers_applied.append(fixer)

                                # update the original match set for
                                # the added code
                                new_matches = self.BM.run(new.leaves())
                                for fxr in new_matches:
                                    if not fxr in match_set:
                                        match_set[fxr]=[]

                                    match_set[fxr].extend(new_matches[fxr])

        for fixer in chain(self.pre_order, self.post_order):
            fixer.finish_tree(tree, name)
        return tree.was_changed

    def traverse_by(self, fixers, traversal):
        """Traverse an AST, applying a set of fixers to each node.

        This is a helper method for refactor_tree().

        Args:
            fixers: a list of fixer instances.
            traversal: a generator that yields AST nodes.

        Returns:
            None
        """
        if not fixers:
            return
        for node in traversal:
            for fixer in fixers[node.type]:
                results = fixer.match(node)
                if results:
                    new = fixer.transform(node, results)
                    if new is not None:
                        node.replace(new)
                        node = new

    def processed_file(self, new_text, filename, old_text=None, write=False,
                       encoding=None):
        """
        Called when a file has been refactored and there may be changes.
        """
        self.files.append(filename)
        if old_text is None:
            old_text = self._read_python_source(filename)[0]
            if old_text is None:
                return
        equal = old_text == new_text
        self.print_output(old_text, new_text, filename, equal)
        if equal:
            self.log_debug("No changes to %s", filename)
            if not self.write_unchanged_files:
                return
        if write:
            self.write_file(new_text, filename, old_text, encoding)
        e